{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "#sentiment analysis\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#keyword Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#visuals\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load bank_reviews dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>bank</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the app is proactive and a good connections.</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cannot send to cbebirr app. through this app.</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not functional</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everytime you uninstall the app you have to re...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date bank  \\\n",
       "0       the app is proactive and a good connections.       5  2025-06-05  CBE   \n",
       "1    I cannot send to cbebirr app. through this app.       3  2025-06-05  CBE   \n",
       "2                                               good       4  2025-06-05  CBE   \n",
       "3                                     not functional       1  2025-06-05  CBE   \n",
       "4  everytime you uninstall the app you have to re...       1  2025-06-04  CBE   \n",
       "\n",
       "        source  \n",
       "0  Google Play  \n",
       "1  Google Play  \n",
       "2  Google Play  \n",
       "3  Google Play  \n",
       "4  Google Play  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6670 entries, 0 to 6669\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  6669 non-null   object\n",
      " 1   rating  6670 non-null   int64 \n",
      " 2   date    6670 non-null   object\n",
      " 3   bank    6670 non-null   object\n",
      " 4   source  6670 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 260.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            the app is proactive and a good connections.\n",
       "1         I cannot send to cbebirr app. through this app.\n",
       "2                                                    good\n",
       "3                                          not functional\n",
       "4       everytime you uninstall the app you have to re...\n",
       "                              ...                        \n",
       "6665                                            Nice one.\n",
       "6666                           ·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï üá™üáπ\n",
       "6667         Best applicationüëçThank you ! Abyssinia bank.\n",
       "6668    Absolutely it's fantastic apps this New apps i...\n",
       "6669           The best app next to Tele birr in ethiopia\n",
       "Name: review, Length: 6670, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data¬∂\n",
    "Steps:\n",
    "\n",
    "1. Clean text: Remove punctuation, special characters, convert to lowercase.\n",
    "2. Tokenize: Split text into words.\n",
    "3. Remove stop words: Eliminate common words (e.g., \"the,\" \"and\").\n",
    "4. Lemmatize: Reduce words to base form (e.g., \"running\" ‚Üí \"run\").\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As shown the reveiw column in our data contains Amharic sentences so I have to translate it first to English\n",
    "### Use Google Translate API\n",
    "### Step 1: Install googletrans\n",
    "### pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Translate Function\n",
    "### Step 3: Apply Translation to Amharic Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\smith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\smith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\smith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\smith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "Language detection failed: No features in text.\n",
      "                                              review lang  \\\n",
      "0       the app is proactive and a good connections.   en   \n",
      "1    I cannot send to cbebirr app. through this app.   en   \n",
      "2                                               good   so   \n",
      "3                                     not functional   en   \n",
      "4  everytime you uninstall the app you have to re...   en   \n",
      "\n",
      "                                   translated_review  \n",
      "0       the app is proactive and a good connections.  \n",
      "1    I cannot send to cbebirr app. through this app.  \n",
      "2                                               good  \n",
      "3                                     not functional  \n",
      "4  everytime you uninstall the app you have to re...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from translate import Translator\n",
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "# Clean string: remove extra spaces and symbols\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    return re.sub(r'[^\\w\\s]', '', text).strip()\n",
    "\n",
    "# Language detection with fallback\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        clean = clean_text(text)\n",
    "        if not clean or len(clean) < 3:  # skip very short texts\n",
    "            return 'unknown'\n",
    "        return detect(clean)\n",
    "    except Exception as e:\n",
    "        print(f\"Language detection failed: {e}\")\n",
    "        return 'unknown'\n",
    "\n",
    "# Translate using 'translate' library\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text\n",
    "        translator = Translator(to_lang=\"en\")\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        return text\n",
    "\n",
    "# --- Load your real dataframe here ---\n",
    "# Make sure 'review' column exists\n",
    "# Example only (remove this if your own df is loaded)\n",
    "# df = pd.DataFrame({'review': [...]})\n",
    "\n",
    "# Clean and filter empty rows\n",
    "df = df[df['review'].notna()]\n",
    "df['review'] = df['review'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['review'] != '']  # Remove empty strings\n",
    "\n",
    "# Detect language\n",
    "df['lang'] = df['review'].apply(detect_lang)\n",
    "\n",
    "# Translate if not English\n",
    "df['translated_review'] = df.apply(\n",
    "    lambda row: translate_to_english(row['review']) if row['lang'] != 'en' else row['review'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# View result\n",
    "print(df[['review', 'lang', 'translated_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # or np.nan if you want to preserve NaNs\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_review'] = df['translated_review'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>bank</th>\n",
       "      <th>source</th>\n",
       "      <th>lang</th>\n",
       "      <th>translated_review</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the app is proactive and a good connections.</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>the app is proactive and a good connections.</td>\n",
       "      <td>app proactive good connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cannot send to cbebirr app. through this app.</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>I cannot send to cbebirr app. through this app.</td>\n",
       "      <td>send cbebirr app app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>so</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not functional</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>not functional</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everytime you uninstall the app you have to re...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>everytime you uninstall the app you have to re...</td>\n",
       "      <td>everytime uninstall app reach physically oldy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>Nice one.</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>BOA</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>Nice one.</td>\n",
       "      <td>nice one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï üá™üáπ</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>BOA</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>unknown</td>\n",
       "      <td>·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï üá™üáπ</td>\n",
       "      <td>·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>Best applicationüëçThank you ! Abyssinia bank.</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>BOA</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>Best applicationüëçThank you ! Abyssinia bank.</td>\n",
       "      <td>best abyssinia bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>Absolutely it's fantastic apps this New apps i...</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>BOA</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>Absolutely it's fantastic apps this New apps i...</td>\n",
       "      <td>absolutely fantastic apps new apps fast good apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>The best app next to Tele birr in ethiopia</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>BOA</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>en</td>\n",
       "      <td>The best app next to Tele birr in ethiopia</td>\n",
       "      <td>best app next tele birr ethiopia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6669 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating        date  \\\n",
       "0          the app is proactive and a good connections.       5  2025-06-05   \n",
       "1       I cannot send to cbebirr app. through this app.       3  2025-06-05   \n",
       "2                                                  good       4  2025-06-05   \n",
       "3                                        not functional       1  2025-06-05   \n",
       "4     everytime you uninstall the app you have to re...       1  2025-06-04   \n",
       "...                                                 ...     ...         ...   \n",
       "6665                                          Nice one.       5  2024-01-14   \n",
       "6666                         ·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï üá™üáπ       5  2024-01-14   \n",
       "6667       Best applicationüëçThank you ! Abyssinia bank.       5  2024-01-12   \n",
       "6668  Absolutely it's fantastic apps this New apps i...       5  2024-01-11   \n",
       "6669         The best app next to Tele birr in ethiopia       5  2024-01-10   \n",
       "\n",
       "     bank       source     lang  \\\n",
       "0     CBE  Google Play       en   \n",
       "1     CBE  Google Play       en   \n",
       "2     CBE  Google Play       so   \n",
       "3     CBE  Google Play       en   \n",
       "4     CBE  Google Play       en   \n",
       "...   ...          ...      ...   \n",
       "6665  BOA  Google Play       en   \n",
       "6666  BOA  Google Play  unknown   \n",
       "6667  BOA  Google Play       en   \n",
       "6668  BOA  Google Play       en   \n",
       "6669  BOA  Google Play       en   \n",
       "\n",
       "                                      translated_review  \\\n",
       "0          the app is proactive and a good connections.   \n",
       "1       I cannot send to cbebirr app. through this app.   \n",
       "2                                                  good   \n",
       "3                                        not functional   \n",
       "4     everytime you uninstall the app you have to re...   \n",
       "...                                                 ...   \n",
       "6665                                          Nice one.   \n",
       "6666                         ·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï üá™üáπ   \n",
       "6667       Best applicationüëçThank you ! Abyssinia bank.   \n",
       "6668  Absolutely it's fantastic apps this New apps i...   \n",
       "6669         The best app next to Tele birr in ethiopia   \n",
       "\n",
       "                                       processed_review  \n",
       "0                         app proactive good connection  \n",
       "1                                  send cbebirr app app  \n",
       "2                                                  good  \n",
       "3                                            functional  \n",
       "4     everytime uninstall app reach physically oldy ...  \n",
       "...                                                 ...  \n",
       "6665                                           nice one  \n",
       "6666                            ·â†·å£·àù ·ã∞·àµ ·ã®·àö·àç ·àà·ãç·å• ·ä†·äì·àò·à∞·åç·äì·àà·äï  \n",
       "6667                                best abyssinia bank  \n",
       "6668  absolutely fantastic apps new apps fast good apps  \n",
       "6669                   best app next tele birr ethiopia  \n",
       "\n",
       "[6669 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis (VADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\smith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_score'] = df['review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "df['sentiment_label'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0.05 else 'negative' if x < -0.05 else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader_sentiment\n",
      "positive    3692\n",
      "neutral     2185\n",
      "negative     792\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    if scores['compound'] > 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply VADER sentiment analysis\n",
    "df['vader_sentiment'] = df['processed_review'].apply(get_vader_sentiment)\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(df['vader_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with TextBlob¬∂\n",
    "#### Description: TextBlob provides a straightforward way to classify sentiments based on polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    3533\n",
      "neutral     2437\n",
      "negative     699\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['processed_review'].apply(get_sentiment)\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Sentiment Analysis with Machine Learning\n",
    "\n",
    "Description: Machine learning models like Naive Bayes improve accuracy by training on labeled data.\n",
    "\n",
    "**Steps**:\n",
    "* Use star ratings as labels (e.g., 4-5 stars = positive, 1-2 stars = negative).\n",
    "* Extract features using TF-IDF.\n",
    "* Train and evaluate a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7698650674662668\n"
     ]
    }
   ],
   "source": [
    "# Create labels based on ratings\n",
    "df['label'] = df['rating'].apply(lambda x: 'positive' if x >= 4 else ('negative' if x <= 2 else 'neutral'))\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['processed_review'])\n",
    "y = df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Sentiment by Bank and Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_summary = df.groupby(['bank', 'rating'])['sentiment_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOA</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.175629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOA</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.053766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOA</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOA</td>\n",
       "      <td>4</td>\n",
       "      <td>0.245347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.323730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CBE</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBE</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.011260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.158479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.317414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CBE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.364923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dashen</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dashen</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.085565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dashen</td>\n",
       "      <td>3</td>\n",
       "      <td>0.303873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dashen</td>\n",
       "      <td>4</td>\n",
       "      <td>0.264967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dashen</td>\n",
       "      <td>5</td>\n",
       "      <td>0.551980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bank  rating  sentiment_score\n",
       "0      BOA       1        -0.175629\n",
       "1      BOA       2        -0.053766\n",
       "2      BOA       3         0.115394\n",
       "3      BOA       4         0.245347\n",
       "4      BOA       5         0.323730\n",
       "5      CBE       1        -0.092763\n",
       "6      CBE       2        -0.011260\n",
       "7      CBE       3         0.158479\n",
       "8      CBE       4         0.317414\n",
       "9      CBE       5         0.364923\n",
       "10  Dashen       1        -0.002916\n",
       "11  Dashen       2        -0.085565\n",
       "12  Dashen       3         0.303873\n",
       "13  Dashen       4         0.264967\n",
       "14  Dashen       5         0.551980"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction (TF-IDF)\n",
    "\n",
    "##### Description: TF-IDF identifies words that are important in specific reviews relative to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords: ['access' 'account' 'add' 'also' 'always' 'amazing' 'app' 'application'\n",
      " 'apps' 'bad' 'balance' 'bank' 'banking' 'best' 'better' 'birr' 'branch'\n",
      " 'ca' 'cbe' 'code' 'could' 'customer' 'dashen' 'day' 'developer' 'easy'\n",
      " 'error' 'ethiopia' 'even' 'ever' 'every' 'excellent' 'experience' 'fast'\n",
      " 'feature' 'fix' 'friendly' 'get' 'go' 'good' 'great' 'help' 'history'\n",
      " 'issue' 'keep' 'life' 'like' 'love' 'make' 'mobile' 'money' 'much' 'need'\n",
      " 'network' 'new' 'nice' 'one' 'open' 'option' 'payment' 'phone' 'please'\n",
      " 'previous' 'problem' 'properly' 'really' 'recent' 'say' 'security' 'see'\n",
      " 'send' 'service' 'show' 'simple' 'sometimes' 'super' 'system' 'thank'\n",
      " 'thanks' 'thing' 'time' 'transaction' 'transfer' 'try' 'update' 'updated'\n",
      " 'use' 'used' 'user' 'using' 'verification' 'version' 'well' 'work'\n",
      " 'working' 'worst' 'would' 'wow' '·â†·å£·àù' '·äê·ãç']\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the dataset\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(df['processed_review'])\n",
    "\n",
    "# Get top keywords\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "print(\"Top Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Sentiment Analysis and Keyword Extraction\n",
    "\n",
    "Description: Analyze keywords in positive vs. negative reviews to understand user preferences and issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords in Positive Reviews: ['app' 'application' 'bank' 'best' 'easy' 'fast' 'good' 'nice'\n",
      " 'transaction' 'use']\n",
      "Top Keywords in Negative Reviews: ['account' 'app' 'bad' 'bank' 'money' 'time' 'transaction' 'update' 'work'\n",
      " 'worst']\n"
     ]
    }
   ],
   "source": [
    "# Filter positive and negative reviews\n",
    "positive_reviews = df[df['sentiment'] == 'positive']['processed_review']\n",
    "negative_reviews = df[df['sentiment'] == 'negative']['processed_review']\n",
    "\n",
    "# Extract keywords from positive reviews\n",
    "vectorizer_pos = TfidfVectorizer(max_features=10)\n",
    "X_pos = vectorizer_pos.fit_transform(positive_reviews)\n",
    "print(\"Top Keywords in Positive Reviews:\", vectorizer_pos.get_feature_names_out())\n",
    "\n",
    "# Extract keywords from negative reviews\n",
    "vectorizer_neg = TfidfVectorizer(max_features=10)\n",
    "X_neg = vectorizer_neg.fit_transform(negative_reviews)\n",
    "print(\"Top Keywords in Negative Reviews:\", vectorizer_neg.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bank_reviews_with_sentiment_themes.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
